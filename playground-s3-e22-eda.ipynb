{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yaaangzhou/playground-s3-e22-eda-modeling?scriptVersionId=142802848\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Created by Yang Zhou**\n\n**[PLAYGROUND S-3,E-22] ðŸ“ŠEDA**\n\n**12 Sep 2023**","metadata":{}},{"cell_type":"markdown","source":"# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">Predict Health Outcomes of Horses</center>\n<p><center style=\"color:#949494; font-family: consolas; font-size: 20px;\">Playground Series - Season 3, Episode 22</center></p>\n\n***\n\n# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">Insights and Tricks</center>\n\n+ Note that there are some columns in the test dataset that have data imbalances.\n\n+ The column `hosptial number` should be a categorical variable because it represents the numbers of different hospitals.\n\n+ In column `pain`, different sub-labels appear in the test data and training data. `moderate` appeared in the test data and not in training data. The way I handle this situation is to OneHot encode after merging the test and training data.","metadata":{}},{"cell_type":"markdown","source":"# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">Version Detail</center>\n\n| Version | Description | Public Score |\n|---------|-------------|-----------------|\n| Version 2 | Add ML models |  |\n| Version 1 | Autogluon Baseline | 0.79878 |","metadata":{}},{"cell_type":"code","source":"!pip install autogluon","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T21:57:09.316071Z","iopub.execute_input":"2023-09-12T21:57:09.316399Z","iopub.status.idle":"2023-09-12T21:59:45.625419Z","shell.execute_reply.started":"2023-09-12T21:57:09.316373Z","shell.execute_reply":"2023-09-12T21:59:45.624758Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0. Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport math\nfrom scipy import stats\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom collections import Counter\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Preprocessing\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, PowerTransformer, QuantileTransformer, OrdinalEncoder, LabelEncoder\nfrom sklearn.impute import SimpleImputer\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import KFold\nimport autogluon as ag\n\n# Models\nfrom sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.ensemble import VotingClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# Metrics\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import mean_squared_log_error \nfrom sklearn.metrics import r2_score \nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.metrics import auc\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T21:59:49.217469Z","iopub.execute_input":"2023-09-12T21:59:49.217865Z","iopub.status.idle":"2023-09-12T21:59:50.489743Z","shell.execute_reply.started":"2023-09-12T21:59:49.217813Z","shell.execute_reply":"2023-09-12T21:59:50.489073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adjusting plot style\n\nrc = {\n    \"axes.facecolor\": \"#F8F8F8\",\n    \"figure.facecolor\": \"#F8F8F8\",\n    \"axes.edgecolor\": \"#000000\",\n    \"grid.color\": \"#EBEBE7\" + \"30\",\n    \"font.family\": \"serif\",\n    \"axes.labelcolor\": \"#000000\",\n    \"xtick.color\": \"#000000\",\n    \"ytick.color\": \"#000000\",\n    \"grid.alpha\": 0.4\n}\n\nsns.set(rc=rc)\npalette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n\nfrom colorama import Style, Fore\nblk = Style.BRIGHT + Fore.BLACK\nmgt = Style.BRIGHT + Fore.MAGENTA\nred = Style.BRIGHT + Fore.RED\nblu = Style.BRIGHT + Fore.BLUE\nres = Style.RESET_ALL","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-09-12T21:59:50.491077Z","iopub.execute_input":"2023-09-12T21:59:50.491463Z","iopub.status.idle":"2023-09-12T21:59:50.497252Z","shell.execute_reply.started":"2023-09-12T21:59:50.49144Z","shell.execute_reply":"2023-09-12T21:59:50.49664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Load Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s3e22/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e22/test.csv')\n# origin = pd.read_csv('/kaggle/input/horse-survival-dataset/horse.csv')\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s3e22/sample_submission.csv')\n\n# Drop column id\n\ntrain.drop('id',axis=1,inplace=True)\ntest.drop('id',axis=1,inplace=True)\n\ntotal = pd.concat([train, test], ignore_index=True)\ntotal = total.drop_duplicates()\ntotal\n\nprint('The shape of the train data:', train.shape)\nprint('The shape of the test data:', test.shape)\n# print('The shape of the origin data:', origin.shape)\nprint('The shape of the total data:', total.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:39:42.828985Z","iopub.execute_input":"2023-09-12T22:39:42.829337Z","iopub.status.idle":"2023-09-12T22:39:42.871183Z","shell.execute_reply.started":"2023-09-12T22:39:42.829308Z","shell.execute_reply":"2023-09-12T22:39:42.869818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:51:36.838078Z","iopub.execute_input":"2023-09-12T15:51:36.83866Z","iopub.status.idle":"2023-09-12T15:51:36.889169Z","shell.execute_reply.started":"2023-09-12T15:51:36.838601Z","shell.execute_reply":"2023-09-12T15:51:36.88785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. EDA\n","metadata":{}},{"cell_type":"code","source":"num_var = [column for column in train.columns if train[column].nunique() > 10]\n\nbin_var = [column for column in train.columns if train[column].nunique() == 2]\ncat_var = [column for column in train.columns if train[column].nunique() < 10]\ncat_var.remove('outcome')\n\ntarget = 'outcome'","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:03:33.380575Z","iopub.execute_input":"2023-09-12T22:03:33.382711Z","iopub.status.idle":"2023-09-12T22:03:33.401497Z","shell.execute_reply.started":"2023-09-12T22:03:33.382665Z","shell.execute_reply":"2023-09-12T22:03:33.40037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe().T\\\n    .style.bar(subset=['mean'], color=px.colors.qualitative.G10[2])\\\n    .background_gradient(subset=['std'], cmap='Blues')\\\n    .background_gradient(subset=['50%'], cmap='BuGn')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:51:36.978886Z","iopub.execute_input":"2023-09-12T15:51:36.979214Z","iopub.status.idle":"2023-09-12T15:51:37.174869Z","shell.execute_reply.started":"2023-09-12T15:51:36.979187Z","shell.execute_reply":"2023-09-12T15:51:37.173876Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**`Hospital number` should appear as a categorical variable, I will handle in feature engineering.**","metadata":{}},{"cell_type":"code","source":"def summary(df):\n    sum = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    sum['missing#'] = df.isna().sum()\n    sum['missing%'] = (df.isna().sum())/len(df)\n    sum['uniques'] = df.nunique().values\n    sum['count'] = df.count().values\n    #sum['skew'] = df.skew().values\n    return sum\n\nsummary(train).style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:51:37.176391Z","iopub.execute_input":"2023-09-12T15:51:37.177455Z","iopub.status.idle":"2023-09-12T15:51:37.244745Z","shell.execute_reply.started":"2023-09-12T15:51:37.177419Z","shell.execute_reply":"2023-09-12T15:51:37.243535Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are more missing cases in `rectal_exam_feces` and `abdomen` columns.**","metadata":{}},{"cell_type":"markdown","source":"**First, i want to look at the distribution of categorical features. Include the target.**","metadata":{}},{"cell_type":"code","source":"columns_cat = [column for column in train.columns if train[column].nunique() < 10]\n\ndef plot_count(df,columns,n_cols):\n    '''\n    # Function to genear countplot\n    df: total data\n    columns: category variables\n    n_cols: num of cols\n    '''\n    n_rows = (len(columns) - 1) // n_cols + 1\n    fig, ax = plt.subplots(n_rows, n_cols, figsize=(17, 4 * n_rows))\n    ax = ax.flatten()\n    \n    for i, column in enumerate(columns):\n        sns.countplot(data=df, x=column, ax=ax[i])\n\n        # Titles\n        ax[i].set_title(f'{column} Counts', fontsize=18)\n        ax[i].set_xlabel(None, fontsize=16)\n        ax[i].set_ylabel(None, fontsize=16)\n        ax[i].tick_params(axis='x', rotation=10)\n\n        for p in ax[i].patches:\n            value = int(p.get_height())\n            ax[i].annotate(f'{value:.0f}', (p.get_x() + p.get_width() / 2, p.get_height()),\n                           ha='center', va='bottom', fontsize=9)\n\n    ylim_top = ax[i].get_ylim()[1]\n    ax[i].set_ylim(top=ylim_top * 1.1)\n    for i in range(len(columns), len(ax)):\n        ax[i].axis('off')\n\n    # fig.suptitle(plotname, fontsize=25, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \nplot_count(train,columns_cat,3)","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T16:04:39.395244Z","iopub.execute_input":"2023-09-12T16:04:39.395669Z","iopub.status.idle":"2023-09-12T16:04:45.733315Z","shell.execute_reply.started":"2023-09-12T16:04:39.395636Z","shell.execute_reply":"2023-09-12T16:04:45.732279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_cat = [column for column in train.columns if train[column].nunique() < 10 and column != target]\nplot_count(test,columns_cat,3)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T16:08:01.02774Z","iopub.execute_input":"2023-09-12T16:08:01.02842Z","iopub.status.idle":"2023-09-12T16:08:06.950177Z","shell.execute_reply.started":"2023-09-12T16:08:01.028372Z","shell.execute_reply":"2023-09-12T16:08:06.949164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are data imbalances in some features, which are manifested in:**\n1. The `age Counts` column contains a large number of adults.\n2. The `peripheral_pulse_Counts` contains little number of `absent` and `increased`.\n3. It Loos like `lesion_2` and `lesion_3` make no sense.","metadata":{}},{"cell_type":"markdown","source":"**Now let me have a look at numerical features.**","metadata":{}},{"cell_type":"code","source":"def plot_pair(df_train,num_var,target,plotname):\n    '''\n    Funtion to make a pairplot:\n    df_train: total data\n    num_var: a list of numeric variable\n    target: target variable\n    '''\n    g = sns.pairplot(data=df_train, x_vars=num_var, y_vars=num_var, hue=target, corner=True)\n    g._legend.set_bbox_to_anchor((0.8, 0.7))\n    g._legend.set_title(target)\n    g._legend.loc = 'upper center'\n    g._legend.get_title().set_fontsize(14)\n    for item in g._legend.get_texts():\n        item.set_fontsize(14)\n\n    plt.suptitle(plotname, ha='center', fontweight='bold', fontsize=25, y=0.98)\n    plt.show()\n\nplot_pair(train,num_var,target,plotname = 'Scatter Matrix with Target')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T10:02:25.10447Z","iopub.execute_input":"2023-09-12T10:02:25.104828Z","iopub.status.idle":"2023-09-12T10:02:43.069202Z","shell.execute_reply.started":"2023-09-12T10:02:25.104796Z","shell.execute_reply":"2023-09-12T10:02:43.068404Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train[num_var].assign(Source = 'Train'), \n                test[num_var].assign(Source = 'Test')], \n               axis=0, ignore_index = True);\n\nfig, axes = plt.subplots(len(num_var), 3 ,figsize = (16, len(num_var) * 4.2), \n                         gridspec_kw = {'hspace': 0.35, 'wspace': 0.3, 'width_ratios': [0.80, 0.20, 0.20]});\n\nfor i,col in enumerate(num_var):\n    ax = axes[i,0];\n    sns.kdeplot(data = df[[col, 'Source']], x = col, hue = 'Source', ax = ax, linewidth = 2.1)\n    ax.set_title(f\"\\n{col}\",fontsize = 9, fontweight= 'bold');\n    ax.grid(visible=True, which = 'both', linestyle = '--', color='lightgrey', linewidth = 0.75);\n    ax.set(xlabel = '', ylabel = '');\n    ax = axes[i,1];\n    sns.boxplot(data = df.loc[df.Source == 'Train', [col]], y = col, width = 0.25,saturation = 0.90, linewidth = 0.90, fliersize= 2.25, color = '#037d97',\n                ax = ax);\n    ax.set(xlabel = '', ylabel = '');\n    ax.set_title(f\"Train\",fontsize = 9, fontweight= 'bold');\n\n    ax = axes[i,2];\n    sns.boxplot(data = df.loc[df.Source == 'Test', [col]], y = col, width = 0.25, fliersize= 2.25,\n                saturation = 0.6, linewidth = 0.90, color = '#E4591E',\n                ax = ax); \n    ax.set(xlabel = '', ylabel = '');\n    ax.set_title(f\"Test\",fontsize = 9, fontweight= 'bold');\n\nplt.tight_layout();\nplt.show();\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T10:02:43.070321Z","iopub.execute_input":"2023-09-12T10:02:43.071164Z","iopub.status.idle":"2023-09-12T10:02:47.83439Z","shell.execute_reply.started":"2023-09-12T10:02:43.071135Z","shell.execute_reply":"2023-09-12T10:02:47.83356Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It seems like the `lesion_3` doesn't make sense and I will delete it in feature engineering.**","metadata":{}},{"cell_type":"markdown","source":"**Now, let's look at the distribution of numerical features in the training set.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, len(num_var) * 2.5))\n\nfor idx, column in enumerate(num_var):\n    plt.subplot(len(num_var), 2, idx*2+1)\n    sns.histplot(x=column, hue=\"outcome\", data=train, bins=30, kde=True)\n    plt.title(f\"{column} Distribution for outcome\")\n    plt.ylim(0, train[column].value_counts().max() + 10)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:02:47.836021Z","iopub.execute_input":"2023-09-12T10:02:47.836449Z","iopub.status.idle":"2023-09-12T10:02:52.564619Z","shell.execute_reply.started":"2023-09-12T10:02:47.836421Z","shell.execute_reply":"2023-09-12T10:02:52.56356Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix = train[num_var].corr()\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n\nplt.figure(figsize=(15, 12))\nsns.heatmap(corr_matrix, mask=mask, annot=False, cmap='Blues', fmt='.2f', linewidths=1, square=True, annot_kws={\"size\": 9} )\nplt.title('Correlation Matrix', fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:02:52.565806Z","iopub.execute_input":"2023-09-12T10:02:52.566059Z","iopub.status.idle":"2023-09-12T10:02:53.032176Z","shell.execute_reply.started":"2023-09-12T10:02:52.566035Z","shell.execute_reply":"2023-09-12T10:02:53.031124Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Features Selections\n\n+ **During feature selection, I can perform the following tests:**\n    + **For categorical variables, a chi-square test will be performed to observe their relationship with the target.**\n    + **We can also use SFS and RFECV for automatic feature selection.**\n\n**You can find a complete and detailed tutorial in this [notebook](https://www.kaggle.com/code/alvinleenh/ps3e21-6-basic-feature-selection-techniques), written by [DR. ALVINLEENH](https://www.kaggle.com/alvinleenh).**","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"# Mapping target to numbers\ntrain[target] = train[target].map({'died':0,'euthanized':1,'lived':2})\ntotal[target] = total[target].map({'died':0,'euthanized':1,'lived':2})","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:39:48.868551Z","iopub.execute_input":"2023-09-12T22:39:48.868917Z","iopub.status.idle":"2023-09-12T22:39:48.877573Z","shell.execute_reply.started":"2023-09-12T22:39:48.86889Z","shell.execute_reply":"2023-09-12T22:39:48.876574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total = pd.get_dummies(total, columns=['surgery',\n                                             'age',\n                                             'temp_of_extremities',\n                                             'peripheral_pulse',\n                                             'mucous_membrane',\n                                             'capillary_refill_time',\n                                             'pain',\n                                             'peristalsis',\n                                             'abdominal_distention',\n                                             'nasogastric_tube',\n                                             'nasogastric_reflux',\n                                             'rectal_exam_feces',\n                                             'abdomen',\n                                             'abdomo_appearance',\n                                             'surgical_lesion',\n                                             'cp_data'])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:39:49.821256Z","iopub.execute_input":"2023-09-12T22:39:49.821633Z","iopub.status.idle":"2023-09-12T22:39:49.841302Z","shell.execute_reply.started":"2023-09-12T22:39:49.821604Z","shell.execute_reply":"2023-09-12T22:39:49.840176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = total.loc[0:train.index[-1]]\ndf_test = total[total[target].isna()]","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:39:52.092047Z","iopub.execute_input":"2023-09-12T22:39:52.092381Z","iopub.status.idle":"2023-09-12T22:39:52.100406Z","shell.execute_reply.started":"2023-09-12T22:39:52.092353Z","shell.execute_reply":"2023-09-12T22:39:52.099509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def features_engineering(df):\n    # Drop useless cols\n\n    # df_encoded = df.copy()\n    # df_encoded.drop(['lesion_3','lesion_2'],axis = 1, inplace = True)\n    \n    # StandardScaler for numeric features\n    # sc = StandardScaler()\n    # for var in num_var:\n        # df[var] = sc.fit_transform(df[var].values.reshape(-1,1))\n    \n    return df\n\n# train = features_engineering(train)\n# test = features_engineering(test)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:18:40.484214Z","iopub.execute_input":"2023-09-12T22:18:40.484548Z","iopub.status.idle":"2023-09-12T22:18:40.490138Z","shell.execute_reply.started":"2023-09-12T22:18:40.484522Z","shell.execute_reply":"2023-09-12T22:18:40.489155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Modeling","metadata":{}},{"cell_type":"code","source":"content_xgb_cv_scores, content_xgb_preds = list(), list()\ncontent_lgbm_cv_scores, content_lgbm_preds = list(), list()\ncontent_rf_cv_scores, content_rf_preds = list(), list()\ncontent_ens_cv_scores, content_ens_preds = list(), list()\n\nkf = KFold(n_splits=5, random_state=42, shuffle=True)\n\nX = df_train.drop(target,axis=1)\nY = df_train[target]\n\nfor i, (train_ix, test_ix) in enumerate(kf.split(X)):\n    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n    Y_train, Y_test = Y.iloc[train_ix], Y.iloc[test_ix]\n    \n    print('---------------------------------------------------------------')\n    \n    ## RandomForestClassifier\n    rf_content = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, Y_train)\n    rf_pred = rf_content.predict(X_test)   \n    accuracy = accuracy_score(Y_test, rf_pred)  \n    print('Fold', i+1, '==> RandomForestClassifier oof Accuracy score is ==>', accuracy)\n    content_rf_cv_scores.append(accuracy)\n    \n    ## Pred\n    rf_pred_test = rf_content.predict_proba(df_test.drop(target,axis=1))\n    content_rf_preds.append(rf_pred_test)\n    \n    ## XGBClassifer\n    xgb_content = XGBClassifier(n_estimators=100, random_state=42).fit(X_train, Y_train)\n    xgb_pred = xgb_content.predict(X_test)   \n    accuracy_xgb = accuracy_score(Y_test, xgb_pred)  \n    print('Fold', i+1, '==> XGBoost oof Accuracy score is ==>', accuracy_xgb)\n    content_xgb_cv_scores.append(accuracy_xgb)\n    \n    ## Pred\n    xgb_pred_test = xgb_content.predict_proba(df_test.drop(target,axis=1))\n    content_xgb_preds.append(xgb_pred_test)\n    \n    ## LightGBM\n    lgbm_content = LGBMClassifier(n_estimators=100, random_state=42).fit(X_train, Y_train)\n    lgbm_pred = lgbm_content.predict(X_test)   \n    accuracy_lgbm = accuracy_score(Y_test, lgbm_pred)  \n    print('Fold', i+1, '==> LightGBM oof Accuracy score is ==>', accuracy_lgbm)\n    content_lgbm_cv_scores.append(accuracy_lgbm)\n    \n    ## Pred\n    lgbm_pred_test = lgbm_content.predict_proba(df_test.drop(target,axis=1))\n    content_lgbm_preds.append(lgbm_pred_test)\n    \n    ## Ensemble Model\n    voting_classifier = VotingClassifier(estimators=[\n        ('xgb', xgb_content),\n        ('lgbm', lgbm_content),\n        ('rf', rf_content)\n    ], voting='hard')\n    voting_classifier.fit(X_train, Y_train)\n    ensemble_pred = voting_classifier.predict(X_test)\n    accuracy_ens = accuracy_score(Y_test, ensemble_pred)\n    \n    print('Fold', i+1, '==> Ensemble Model oof Accuracy score is ==>', accuracy_ens)\n    content_ens_cv_scores.append(accuracy_ens)\n\nprint('---------------------------------------------------------------')\nprint('Average Accuracy of XGBoost model is:', np.mean(content_xgb_cv_scores))\nprint('Average Accuracy of LGBM model is:', np.mean(content_lgbm_cv_scores))\nprint('Average Accuracy of RF model is:', np.mean(content_rf_cv_scores))\nprint('Average Accuracy of Ensemble Model is:', np.mean(content_ens_cv_scores))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:39:53.910655Z","iopub.execute_input":"2023-09-12T22:39:53.91198Z","iopub.status.idle":"2023-09-12T22:40:29.747864Z","shell.execute_reply.started":"2023-09-12T22:39:53.911933Z","shell.execute_reply":"2023-09-12T22:40:29.746238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Simple Voting Classifer\n\nens_preds = voting_classifier.predict(df_test.drop(target,axis=1))\n\n\nens_submission = pd.DataFrame({'id': sample_submission['id'], 'outcome': ens_preds})\nens_submission['outcome'] = ens_submission['outcome'].map({0:'died',1:'euthanized',2:'lived'})\nens_submission.to_csv('ens_submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:41:20.236609Z","iopub.execute_input":"2023-09-12T22:41:20.236985Z","iopub.status.idle":"2023-09-12T22:41:20.301166Z","shell.execute_reply.started":"2023-09-12T22:41:20.236945Z","shell.execute_reply":"2023-09-12T22:41:20.300123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_md = LGBMClassifier(objective='multiclass',metric='auc_mu',feature_pre_filter=False,num_leaves=248, min_child_samples=20, num_iterations=50, early_stopping_round= None).fit(X,Y)\nlgb_preds = lgb_md.predict(df_test.drop(target,axis=1))\n\nlgb_submission = pd.DataFrame({'id': sample_submission['id'], 'outcome': lgb_preds})\nlgb_submission['outcome'] = lgb_submission['outcome'].map({0:'died',1:'euthanized',2:'lived'})\nlgb_submission.to_csv('ens_submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:50:27.891407Z","iopub.execute_input":"2023-09-12T22:50:27.891765Z","iopub.status.idle":"2023-09-12T22:50:30.047121Z","shell.execute_reply.started":"2023-09-12T22:50:27.891736Z","shell.execute_reply":"2023-09-12T22:50:30.046099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Baseline with Autogluon\n\nAt the beginning, I'm gonna build a baseline model using an automated machine learning framework.","metadata":{}},{"cell_type":"code","source":"from autogluon.tabular import TabularDataset, TabularPredictor\n\n#train_data = TabularDataset('/kaggle/input/playground-series-s3e22/train.csv')\n#test_data = TabularDataset('/kaggle/input/playground-series-s3e22/test.csv')\n\npredictor = TabularPredictor(label='outcome').fit(df_train)\npreds = predictor.predict(df_test.drop(target,axis=1))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-12T22:51:23.411568Z","iopub.execute_input":"2023-09-12T22:51:23.411997Z","iopub.status.idle":"2023-09-12T22:52:13.115943Z","shell.execute_reply.started":"2023-09-12T22:51:23.411964Z","shell.execute_reply":"2023-09-12T22:52:13.114829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = preds.map({0:'died',1:'euthanized',2:'lived'})","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:03:21.411262Z","iopub.status.idle":"2023-09-12T10:03:21.411826Z","shell.execute_reply.started":"2023-09-12T10:03:21.411594Z","shell.execute_reply":"2023-09-12T10:03:21.411613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auto_submission = pd.DataFrame({'id': sample_submission['id'], 'outcome': preds})\nauto_submission.to_csv('auto_submission.csv',index=False)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-09-12T10:03:21.413029Z","iopub.status.idle":"2023-09-12T10:03:21.413898Z","shell.execute_reply.started":"2023-09-12T10:03:21.413716Z","shell.execute_reply":"2023-09-12T10:03:21.413734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auto_submission","metadata":{"execution":{"iopub.status.busy":"2023-09-12T10:03:21.415293Z","iopub.status.idle":"2023-09-12T10:03:21.415655Z","shell.execute_reply.started":"2023-09-12T10:03:21.415469Z","shell.execute_reply":"2023-09-12T10:03:21.415485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}