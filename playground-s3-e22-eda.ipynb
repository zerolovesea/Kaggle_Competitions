{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yaaangzhou/playground-s3-e22-eda-autogluon-baseline?scriptVersionId=142705656\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Created by Yang Zhou**\n\n**[PLAYGROUND S-3,E-22] ðŸ“ŠEDA**\n\n**12 Sep 2023**","metadata":{}},{"cell_type":"markdown","source":"# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">Predict Health Outcomes of Horses</center>\n<p><center style=\"color:#949494; font-family: consolas; font-size: 20px;\">Playground Series - Season 3, Episode 22</center></p>\n\n***\n\n# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">Insights and Tricks</center>\n\n+ The task was to predict the Health outcome of the horse, and as a basic task, the key to achieving a high score was feature engineering.\n\n+ Note that there are some columns in the test dataset that have data imbalances.\n\n+ The column `lesion_3` can be deleted, it has only two records that are not 0 in the training set and all values in the test set are 0.","metadata":{}},{"cell_type":"markdown","source":"# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">Version Detail</center>\n\n| Version | Description | Public Score |\n|---------|-------------|-----------------|\n| Version 1 | Autogluon Baseline | 0.79878 |","metadata":{}},{"cell_type":"code","source":"!pip install autogluon","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T04:31:47.358933Z","iopub.execute_input":"2023-09-12T04:31:47.359516Z","iopub.status.idle":"2023-09-12T04:32:13.125209Z","shell.execute_reply.started":"2023-09-12T04:31:47.359479Z","shell.execute_reply":"2023-09-12T04:32:13.123535Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0. Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport math\nfrom scipy import stats\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.linear_model import SGDOneClassSVM\nfrom sklearn.model_selection import KFold\nimport autogluon as ag\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T04:32:13.130106Z","iopub.execute_input":"2023-09-12T04:32:13.130599Z","iopub.status.idle":"2023-09-12T04:32:13.143083Z","shell.execute_reply.started":"2023-09-12T04:32:13.130545Z","shell.execute_reply":"2023-09-12T04:32:13.141529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adjusting plot style\n\nrc = {\n    \"axes.facecolor\": \"#F8F8F8\",\n    \"figure.facecolor\": \"#F8F8F8\",\n    \"axes.edgecolor\": \"#000000\",\n    \"grid.color\": \"#EBEBE7\" + \"30\",\n    \"font.family\": \"serif\",\n    \"axes.labelcolor\": \"#000000\",\n    \"xtick.color\": \"#000000\",\n    \"ytick.color\": \"#000000\",\n    \"grid.alpha\": 0.4\n}\n\nsns.set(rc=rc)\npalette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n\nfrom colorama import Style, Fore\nblk = Style.BRIGHT + Fore.BLACK\nmgt = Style.BRIGHT + Fore.MAGENTA\nred = Style.BRIGHT + Fore.RED\nblu = Style.BRIGHT + Fore.BLUE\nres = Style.RESET_ALL","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-09-12T04:32:13.145446Z","iopub.execute_input":"2023-09-12T04:32:13.146045Z","iopub.status.idle":"2023-09-12T04:32:13.163062Z","shell.execute_reply.started":"2023-09-12T04:32:13.145995Z","shell.execute_reply":"2023-09-12T04:32:13.161949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Load Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s3e22/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e22/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s3e22/sample_submission.csv')\n\nprint('The shape of the train data:', train.shape)\nprint('The shape of the test data:', test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:44:27.045784Z","iopub.execute_input":"2023-09-12T04:44:27.046275Z","iopub.status.idle":"2023-09-12T04:44:27.088359Z","shell.execute_reply.started":"2023-09-12T04:44:27.04624Z","shell.execute_reply":"2023-09-12T04:44:27.086841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:32:13.229395Z","iopub.execute_input":"2023-09-12T04:32:13.229801Z","iopub.status.idle":"2023-09-12T04:32:13.273085Z","shell.execute_reply.started":"2023-09-12T04:32:13.229767Z","shell.execute_reply":"2023-09-12T04:32:13.271676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. EDA\n","metadata":{}},{"cell_type":"code","source":"num_var = [column for column in train.columns if train[column].nunique() > 10]\nnum_var.remove('id')\n\ncat_var = [column for column in train.columns if train[column].nunique() < 10]\ncat_var.remove('outcome')\n\ntarget = 'outcome'","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:44:28.7841Z","iopub.execute_input":"2023-09-12T04:44:28.784647Z","iopub.status.idle":"2023-09-12T04:44:28.805244Z","shell.execute_reply.started":"2023-09-12T04:44:28.784605Z","shell.execute_reply":"2023-09-12T04:44:28.80375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe().T\\\n    .style.bar(subset=['mean'], color=px.colors.qualitative.G10[2])\\\n    .background_gradient(subset=['std'], cmap='Blues')\\\n    .background_gradient(subset=['50%'], cmap='BuGn')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:32:13.286934Z","iopub.execute_input":"2023-09-12T04:32:13.288Z","iopub.status.idle":"2023-09-12T04:32:13.358865Z","shell.execute_reply.started":"2023-09-12T04:32:13.287935Z","shell.execute_reply":"2023-09-12T04:32:13.357435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**`Hospital number` should appear as a categorical variable, I will handle in feature engineering.**","metadata":{}},{"cell_type":"code","source":"def summary(df):\n    sum = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    sum['missing#'] = df.isna().sum()\n    sum['missing%'] = (df.isna().sum())/len(df)\n    sum['uniques'] = df.nunique().values\n    sum['count'] = df.count().values\n    #sum['skew'] = df.skew().values\n    return sum\n\nsummary(train).style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:38:45.10597Z","iopub.execute_input":"2023-09-12T04:38:45.106488Z","iopub.status.idle":"2023-09-12T04:38:45.168754Z","shell.execute_reply.started":"2023-09-12T04:38:45.106447Z","shell.execute_reply":"2023-09-12T04:38:45.167467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are more missing cases in `rectal_exam_feces` and `abdomen` columns.**","metadata":{}},{"cell_type":"markdown","source":"**First, i want to look at the distribution of categorical features. Include the target.**","metadata":{}},{"cell_type":"code","source":"columns_cat = [column for column in train.columns if train[column].nunique() < 10]\n\ndef plot_count(df,columns,n_cols):\n    '''\n    # Function to genear countplot\n    df: total data\n    columns: category variables\n    n_cols: num of cols\n    '''\n    n_rows = (len(columns) - 1) // n_cols + 1\n    fig, ax = plt.subplots(n_rows, n_cols, figsize=(17, 4 * n_rows))\n    ax = ax.flatten()\n    \n    for i, column in enumerate(columns):\n        sns.countplot(data=df, x=column, ax=ax[i])\n\n        # Titles\n        ax[i].set_title(f'{column} Counts', fontsize=18)\n        ax[i].set_xlabel(None, fontsize=16)\n        ax[i].set_ylabel(None, fontsize=16)\n        ax[i].tick_params(axis='x', rotation=10)\n\n        for p in ax[i].patches:\n            value = int(p.get_height())\n            ax[i].annotate(f'{value:.0f}', (p.get_x() + p.get_width() / 2, p.get_height()),\n                           ha='center', va='bottom', fontsize=9)\n\n    ylim_top = ax[i].get_ylim()[1]\n    ax[i].set_ylim(top=ylim_top * 1.1)\n    for i in range(len(columns), len(ax)):\n        ax[i].axis('off')\n\n    # fig.suptitle(plotname, fontsize=25, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \nplot_count(train,columns_cat,3)","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T04:46:01.924948Z","iopub.execute_input":"2023-09-12T04:46:01.925522Z","iopub.status.idle":"2023-09-12T04:46:08.063848Z","shell.execute_reply.started":"2023-09-12T04:46:01.925479Z","shell.execute_reply":"2023-09-12T04:46:08.062582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are data imbalances in some features, which are manifested in:**\n1. The `age Counts` column contains a large number of adults.\n2. The `peripheral_pulse_Counts` contains little number of `absent` and `increased`.\n3. It Loos like `lesion_2` and `lesion_3` make no sense.","metadata":{}},{"cell_type":"markdown","source":"**Let's have a look at numerical features.**","metadata":{}},{"cell_type":"code","source":"def plot_pair(df_train,num_var,target,plotname):\n    '''\n    Funtion to make a pairplot:\n    df_train: total data\n    num_var: a list of numeric variable\n    target: target variable\n    '''\n    g = sns.pairplot(data=df_train, x_vars=num_var, y_vars=num_var, hue=target, corner=True)\n    g._legend.set_bbox_to_anchor((0.8, 0.7))\n    g._legend.set_title(target)\n    g._legend.loc = 'upper center'\n    g._legend.get_title().set_fontsize(14)\n    for item in g._legend.get_texts():\n        item.set_fontsize(14)\n\n    plt.suptitle(plotname, ha='center', fontweight='bold', fontsize=25, y=0.98)\n    plt.show()\n\nplot_pair(train,num_var,target,plotname = 'Scatter Matrix with Target')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T04:38:58.225051Z","iopub.execute_input":"2023-09-12T04:38:58.226184Z","iopub.status.idle":"2023-09-12T04:39:26.131414Z","shell.execute_reply.started":"2023-09-12T04:38:58.226125Z","shell.execute_reply":"2023-09-12T04:39:26.130142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train[num_var].assign(Source = 'Train'), \n                test[num_var].assign(Source = 'Test')], \n               axis=0, ignore_index = True);\n\nfig, axes = plt.subplots(len(num_var), 3 ,figsize = (16, len(num_var) * 4.2), \n                         gridspec_kw = {'hspace': 0.35, 'wspace': 0.3, 'width_ratios': [0.80, 0.20, 0.20]});\n\nfor i,col in enumerate(num_var):\n    ax = axes[i,0];\n    sns.kdeplot(data = df[[col, 'Source']], x = col, hue = 'Source', ax = ax, linewidth = 2.1)\n    ax.set_title(f\"\\n{col}\",fontsize = 9, fontweight= 'bold');\n    ax.grid(visible=True, which = 'both', linestyle = '--', color='lightgrey', linewidth = 0.75);\n    ax.set(xlabel = '', ylabel = '');\n    ax = axes[i,1];\n    sns.boxplot(data = df.loc[df.Source == 'Train', [col]], y = col, width = 0.25,saturation = 0.90, linewidth = 0.90, fliersize= 2.25, color = '#037d97',\n                ax = ax);\n    ax.set(xlabel = '', ylabel = '');\n    ax.set_title(f\"Train\",fontsize = 9, fontweight= 'bold');\n\n    ax = axes[i,2];\n    sns.boxplot(data = df.loc[df.Source == 'Test', [col]], y = col, width = 0.25, fliersize= 2.25,\n                saturation = 0.6, linewidth = 0.90, color = '#E4591E',\n                ax = ax); \n    ax.set(xlabel = '', ylabel = '');\n    ax.set_title(f\"Test\",fontsize = 9, fontweight= 'bold');\n\nplt.tight_layout();\nplt.show();\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-12T04:41:23.580878Z","iopub.execute_input":"2023-09-12T04:41:23.58153Z","iopub.status.idle":"2023-09-12T04:41:31.021543Z","shell.execute_reply.started":"2023-09-12T04:41:23.58148Z","shell.execute_reply":"2023-09-12T04:41:31.020135Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It seems like the `lesion_3` doesn't make sense and I will delete it in feature engineering.**","metadata":{}},{"cell_type":"markdown","source":"**Now, let's look at the distribution of numerical features in the training set.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, len(num_var) * 2.5))\n\nfor idx, column in enumerate(num_var):\n    plt.subplot(len(num_var), 2, idx*2+1)\n    sns.histplot(x=column, hue=\"outcome\", data=train, bins=30, kde=True)\n    plt.title(f\"{column} Distribution for outcome\")\n    plt.ylim(0, train[column].value_counts().max() + 10)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:33:38.594385Z","iopub.execute_input":"2023-09-12T04:33:38.594804Z","iopub.status.idle":"2023-09-12T04:33:49.460594Z","shell.execute_reply.started":"2023-09-12T04:33:38.594769Z","shell.execute_reply":"2023-09-12T04:33:49.459473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix = train[num_var].corr()\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n\nplt.figure(figsize=(15, 12))\nsns.heatmap(corr_matrix, mask=mask, annot=False, cmap='Blues', fmt='.2f', linewidths=1, square=True, annot_kws={\"size\": 9} )\nplt.title('Correlation Matrix', fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:33:49.46224Z","iopub.execute_input":"2023-09-12T04:33:49.463407Z","iopub.status.idle":"2023-09-12T04:33:50.171429Z","shell.execute_reply.started":"2023-09-12T04:33:49.463368Z","shell.execute_reply":"2023-09-12T04:33:50.170253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Features Selections\n\n+ During feature selection, I can perform the following tests:\n    + For categorical variables, a chi-square test will be performed to observe their relationship with the target.\n    + We can also use SFS and RFECV for automatic feature selection.\n\nYou can find a complete and detailed tutorial in this [notebook](https://www.kaggle.com/code/alvinleenh/ps3e21-6-basic-feature-selection-techniques), written by [DR. ALVINLEENH](https://www.kaggle.com/alvinleenh).","metadata":{}},{"cell_type":"code","source":"def features_engineering(df):\n    \n    # StandardScaler for numeric features\n    sc = StandardScaler()\n    for var in num_var:\n        df[var] = sc.fit_transform(df[var].values.reshape(-1,1))\n    \n    # LabelEncoder for cat features\n    lc = LabelEncoder()\n    for var in cat_var:\n        df[var] =lc.fit_transform(df[var])\n    \n    # Drop useless cols\n    df.drop(['id','lesion_3'],axis = 1, inplace = True)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:46:33.213272Z","iopub.execute_input":"2023-09-12T04:46:33.213783Z","iopub.status.idle":"2023-09-12T04:46:33.225762Z","shell.execute_reply.started":"2023-09-12T04:46:33.213745Z","shell.execute_reply":"2023-09-12T04:46:33.224529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = features_engineering(train)\ntest = features_engineering(test)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:46:52.534124Z","iopub.execute_input":"2023-09-12T04:46:52.534887Z","iopub.status.idle":"2023-09-12T04:46:52.591955Z","shell.execute_reply.started":"2023-09-12T04:46:52.534845Z","shell.execute_reply":"2023-09-12T04:46:52.590482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Baseline with Autogluon\n\nAt the beginning, I'm gonna build a baseline model using an automated machine learning framework.","metadata":{}},{"cell_type":"code","source":"from autogluon.tabular import TabularDataset, TabularPredictor\n\n#train_data = TabularDataset('/kaggle/input/playground-series-s3e22/train.csv')\n#test_data = TabularDataset('/kaggle/input/playground-series-s3e22/test.csv')\n\npredictor = TabularPredictor(label='outcome').fit(train)\npreds = predictor.predict(test)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-12T04:46:54.120326Z","iopub.execute_input":"2023-09-12T04:46:54.120864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auto_submission = pd.DataFrame({'id': sample_submission['id'], 'outcome': preds})\nauto_submission.to_csv('auto_submission.csv',index=False)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}